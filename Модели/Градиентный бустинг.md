Градиентный бустинг (gradient boosting) — ансамблевый метод машинного обучения, который строит сильную модель, последовательно добавляя слабые модели, предсказывающие ошибки. Таким образом, итеративно сильная модель аддитивно обучается лучше корректировать ошибки.

| Характеристика               | Значение                                                     |
| :--------------------------- | :----------------------------------------------------------- |
| Задача                       | Регрессия, многоклассовая классификация                      |
| Тип обучения                 | Обучение с учителем                                          |
| Множество целевой переменной | Регрессия: $\mathbb{R}$ <br>Классификация: $\{0, \dots, K\}$ |
| Тип ансамбля                 | Бустинг                                                      |

# Обучение

Пусть есть:

- $M$ слабых моделей $h_m(\mathbf{x})$, $m \in \{1, \dots, M\}$
- Скорость обучения $\nu$

Алгоритм:

1. Инициализировать константную модель $F_0(x)$, например, предсказывающую среднее тренировочных данных $\overline{y}$.
2. Для каждой слабой модели $h_m(\mathbf{x})$:
	1. Для каждого объекта вычислить остатки текущей сильной модели: $r_{i} = y_{i} - \hat{y}_i$
	2. Обучить $h_m(\mathbf{x})$ предсказывать $r$.
	3. Обновить сильную модель:
        $F_m(x) = F_{m-1}(x) + \nu \cdot h_m(\mathbf{x})$

## Гиперпараметры

Подход к обучению:

* Количество слабых моделей;
* Скорость обучения;
* Использование случайного подмножества тренировочных данных на каждой итерации для обучения новой базовой модели.
* Использование случайного подмножества признаков для каждого сплита в базовых деревьях.
* Гиперпараметры слабых моделей.

Условия остановки:

* Максимальное количество итераций обучения;
* Минимальное изменение функции потерь для продолжения обучения;
* Ранняя остановка (early stopping) на валидационном наборе: прекращение обучения, если производительность на валидационном наборе перестаёт улучшаться.

## Функции потерь

Регрессия:

| Название                    | Описание                                                                              | Обозначение  | Формула                                                     |
| --------------------------- | ------------------------------------------------------------------------------------- | ------------ | ----------------------------------------------------------- |
| Средняя квадратичная ошибка | Среднее значение квадратов разностей между $N$ истинными и предсказанными значениями. | $\text{MSE}$ | $\frac{\sum_{i=1}^{N} \left( y_i - \hat{y}_i \right)^2}{N}$ |
| Средняя абсолютная ошибка   | Среднее значение модулей разностей между $N$ истинными и предсказанными значениями.   | $\text{MAE}$ | $\frac{\sum_{i=1}^{N} \lvert y_i - \hat{y}_i \rvert}{N}$    |

Классификация:

| Название                                     | Описание                                                                                                                                     | Обозначение   | Формула                                                                        |
| -------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------ |
| Средняя двоичная перекрёстная энтропия       | Средняя мера расхождения между истинными бинарными метками и предсказанными вероятностями классов.                                           | $\text{MBCE}$ | $- \frac{\sum_{i=1}^N{[-y_i\ln(\hat{y_i}) - (1 - y_i)\ln(1 - \hat{y_i})]}}{N}$ |
| Средняя многоклассовая перекрёстная энтропия | Средняя мера расхождения между истинным распределением классов и предсказанным распределением вероятностей для многоклассовой классификации. | $\text{MCCE}$ | $-\frac{\sum_{i=1}^{N} \sum_{j=1}^{K} y_{ij} \log(\hat{y}_{ij})}{N}$           |

# Предсказание

Для нового объекта $\mathbf{x}$, предсказание осуществляется путём сложения предсказаний начальной модели и всех обученных слабых моделей с учётом скорости обучения:

$$\hat{y} = F_M(\mathbf{x}) = F_0(\mathbf{x}) + \nu \sum_{m=1}^M h_m(\mathbf{x})$$

# Оценка качества

## Классификация

* [[Метрики качества классификаторов]]
* [[ROC-кривая]]

## Регрессия

- [[Метрики качества регрессоров]]