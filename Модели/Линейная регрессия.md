Линейная регрессия (linear regression) — параметрический алгоритм для задачи регрессии, который моделирует линейную зависимость между независимыми переменными (признаками) и зависимой переменной, подбирая коэффициенты (веса) таким образом, чтобы минимизировать сумму квадратов разностей между фактическими и предсказанными значениями.

| Свойство                     | Значение            |
| ---------------------------- | ------------------- |
| Задача                       | Регрессия           |
| Тип обучения                 | Обучение с учителем |
| Множество целевой переменной | $\mathbb{R}$        |

# Модель

$$\hat{y} = \hat{w_{1}}x_{1} + \hat{w_{2}}x_{2} + \dots + \hat{w_{n}}x_{n} + b$$

# Алгоритмы обучения

Входные данные:

- тренировочные данные.

Процедура, вариант А — стохастический квадратический подход:

1. Выбрать случайные веса и смещение.
2. Повторять до выполнения условия остановки:
	1. Выбрать случайную точку данных.
	2. К свободному члену прибавить $\eta$, умноженное на ошибку. Умножение позволяет определить знак $\eta$ на основании знака ошибки: $\hat{b}' = \hat{b} + \eta (y - \hat{y})$.
	3. К каждому коэффициенту $\hat{\beta_i}$ прибавить $\eta$, умноженное на произведение переменной $x_i$ и ошибки. Умножение позволяет определить знак $\eta$ на основании знака произведения: $\hat{w_i}' = \hat{w_i} + \eta x_i (y - \hat{y})$.

Процедура, вариант Б — минимизация функции потерь (средней квадратической ошибки):

1. Выбрать случайные веса и смещение.
2. Повторять до выполнения условия остановки:
	1. $\hat{b}' = \hat{b} - \eta \frac{\partial MSE}{\partial b}$, $\frac{\partial MSE}{\partial \hat{b}} = -\frac{2}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})$
	   $\hat{w_i}' = \hat{w_i} - \eta \frac{\partial MSE}{\partial \hat{w_i}}$, $\frac{\partial MSE}{\partial \hat{w_j}} = -\frac{2}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})x_{ij}$

> [!Info]
> $$\nabla {MSE} = \left( \frac{\partial MSE}{\partial \hat{b}}, \frac{\partial MSE}{\partial \hat{w_1}}, \ldots, \frac{\partial MSE}{\partial \hat{w_i}} \right)$$

# Гиперпараметры

$\eta$ — скорость обучения (коэффициент для изменения весов и смещения на итерации).

Условия остановки:

- минимальная величина изменения функции потерь в течение нескольких периодов;
- целевое значение функции потерь;
- количество итераций обучения.

# Функция потерь

| Название                                         | Описание                                                                                                                                                                       | Обозначение | Формула                                                                                                 |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------- | ------------------------------------------------------------------------------------------------------- |
| Средняя квадратичная ошибка (Mean Squared Error) | Вычисляет среднее значение квадратов разностей между фактическими и предсказанными значениями. Очень чувствительна к большим ошибкам (выбросам).                               | $MSE$       | $\frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2$                                           |
| Ошибка регрессии LASSO                           | Состоит из $MSE$ и $L1$-штрафа (сумма модулей весов). Штрафует модель за сложность и способна обнулять коэффициенты неважных признаков, выполняя их отбор.                     | $L1$        | $\frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2 + \lambda \sum_{j=1}^{m}\lvert w_j \rvert$ |
| Ошибка гребневой регрессии                       | Состоит из $MSE$ и $L2$-штрафа (сумма квадратов весов). Штрафует модель за большие коэффициенты, делая ее более устойчивой к переобучению, но обычно не обнуляет их полностью. | $L2$        | $\frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2 + \lambda \sum_{j=1}^{m}w_j^2$             |

# Метрики качества

| Название                                                        | Описание                                                                                                                                         | Обозначение | Формула                                                                |
| --------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ | ----------- | ---------------------------------------------------------------------- |
| Средняя квадратичная ошибка (Mean Squared Error)                | Вычисляет среднее значение квадратов разностей между фактическими и предсказанными значениями. Очень чувствительна к большим ошибкам (выбросам). | $MSE$       | $\frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2$          |
| Корень из средней квадратичной ошибки (Root Mean Squared Error) | Квадратный корень из $MSE$. Преимущество в том, что ошибка измеряется в тех же единицах, что и целевая переменная.                               | $RMSE$      | $\sqrt{ \frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2 }$ |
| Средняя абсолютная ошибка (Mean Absolute Error)                 | Вычисляет среднее значение модуля разности между фактическими и предсказанными значениями. Менее чувствительна к выбросам по сравнению с MSE.    | $MAE$       | $\frac{1}{n} \sum_{i=1}^{n} \left\| y_i - \hat{y}_i \right\|$          |
