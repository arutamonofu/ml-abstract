![[random_forest.png]]

Случайный лес (Random Forest) — это ансамблевый непараметрический алгоритм машинного обучения, который строит множество деревьев решений на различных подмножествах данных и признаков, а затем объединяет их предсказания для повышения точности, стабильности и борьбы с переобучением. Для классификации результат определяется большинством голосов деревьев, а для регрессии — усреднением предсказаний.

| Характеристика               | Значение                                                     |
| :--------------------------- | :----------------------------------------------------------- |
| Задача                       | Регрессия, многоклассовая классификация                      |
| Тип обучения                 | Обучение с учителем                                          |
| Множество целевой переменной | Регрессия: $\mathbb{R}$ <br>Классификация: $\{0, \dots, K\}$ |

# Обучение

Алгоритм обучения:

1.  Инициализировать количество деревьев $N$ для построения леса.
2.  Для каждого дерева $k$ выполнить следующие шаги:
    1. Сформировать бутстреп-выборку (случайная выборка с возвращением) из исходного набора данных.
    2. Построить дерево решений на сформированной бутстреп-выборке. При каждом разбиении узла, вместо рассмотрения всех признаков, рассматривать только случайное подмножество признаков.
    3. Выращивать каждое дерево до максимальной глубины или до выполнения других условий остановки, как правило, без последующей обрезки.

## Гиперпараметры

Критерий оценки разделения (для каждого дерева):

| Критерий              | Описание                                                                                                              | Формула                                                                                                                             |
| :-------------------- | :-------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------- |
| Индекс примесей Джини | Вероятность взять случайным образом из набора 2 объекта разных классов.                                               | **Для одного узла:**<br> $G(Y) = 1 – \sum P_i^2$ <br>**Для пары узлов:**<br> $G(Y, X) = \frac{n_1}{n}G_1 + \frac{n_2}{n}G_2$        |
| Энтропия              | Как бы соотносится с вероятностью получить заданную последовательность всех объектов, доставая их случайно из набора. | **Для одного узла:**<br> $E(Y) = -\sum p_i \log_2(p_i)$ <br>**Для пары узлов:**<br> $E(Y, X) = \frac{n_1}{n}E_1 + \frac{n_2}{n}E_2$ |

Другие гиперпараметры:

* Количество деревьев.
* Число признаков, рассматриваемых при каждом разбиении узла (важнейший параметр случайного леса).
* Использовать ли бутстреп-выборку при построении каждого дерева.
* Использовать ли OOB (out-of-bag) образцы для оценки обобщающей способности модели.
* Веса классов при несбалансированной выборке.

Условия остановки и борьба с переобучением (применяются к каждому отдельному дереву):

*   Максимальная глубина.
*   Максимальное количество листьев.
*   Минимальное число объектов в узле для разделения узла.
*   Минимальное число объектов в листьях для разделения узла.
*   Минимальное изменение оценки разделения при разделении.

# Предсказание

## Классификация

Для классификации предсказывается класс, который получил наибольшее количество голосов (большинство) среди всех деревьев в лесу.

## Регрессия

Для регрессии предсказывается среднее (или медианное) значение целевой переменной, предсказанное всеми деревьями в лесу.

# Оценка качества

## Классификация

*   [[Метрики качества классификаторов]]
*   [[ROC-кривая]]

## Регрессия

*   [[Метрики качества регрессоров]]